{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import, load dataset, load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import gzip\n",
    "import os\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from scvi.dataset import GeneExpressionDataset, Dataset10X\n",
    "from scvi.models import VAE, TOTALVI\n",
    "from scvi.inference import TotalPosterior, TotalTrainer, Posterior, UnsupervisedTrainer\n",
    "from totalppc import TotalPosteriorPredictiveCheck as totalPPC\n",
    "\n",
    "import umap\n",
    "\n",
    "sns.set(context=\"notebook\", font_scale=1.15, style=\"ticks\")\n",
    "save_path = \"../data/10X\"\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset10X(dataset_name=\"malt_10k_protein_v3\", save_path=save_path, \n",
    "                     measurement_names_column=1, dense=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dataset(dataset):\n",
    "    high_count_genes = (dataset.X > 0).sum(axis=0).ravel() > 0.01 * dataset.X.shape[0]\n",
    "    dataset.update_genes(high_count_genes)\n",
    "    dataset.subsample_genes(new_n_genes=5000)\n",
    "    high_gene_count_cells = (dataset.X > 0).sum(axis=1).ravel() > 500\n",
    "    # Filter control proteins\n",
    "    non_control_proteins = []\n",
    "    for i, p in enumerate(dataset.protein_names):\n",
    "        if not p.startswith(\"IgG\"):\n",
    "            non_control_proteins.append(i)\n",
    "        else:\n",
    "            print(p)\n",
    "    dataset.protein_expression = dataset.protein_expression[:, non_control_proteins]\n",
    "    dataset.protein_names = dataset.protein_names[non_control_proteins]\n",
    "    \n",
    "    high_protein_cells = dataset.protein_expression.sum(axis=1) >= np.percentile(dataset.protein_expression.sum(axis=1), 1)\n",
    "    inds_to_keep = np.logical_and(high_gene_count_cells, high_protein_cells)\n",
    "    dataset.update_cells(inds_to_keep)\n",
    "    \n",
    "    \n",
    "    return dataset, inds_to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, inds_to_keep = filter_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalvae = TOTALVI(dataset.nb_genes, len(dataset.protein_names), n_latent=20)\n",
    "use_cuda = True\n",
    "lr = 5e-3\n",
    "early_stopping_kwargs = {\n",
    "    \"early_stopping_metric\": \"elbo\",\n",
    "    \"save_best_state_metric\": \"elbo\",\n",
    "    \"patience\": 150,\n",
    "    \"threshold\": 0,\n",
    "    \"reduce_lr_on_plateau\": True,\n",
    "    \"lr_patience\": 30,\n",
    "    \"lr_factor\": 0.6,\n",
    "    \"posterior_class\": TotalPosterior,\n",
    "}\n",
    "\n",
    "trainer = TotalTrainer(\n",
    "    totalvae,\n",
    "    dataset,\n",
    "    train_size=0.90,\n",
    "    test_size=0.04,\n",
    "    use_cuda=use_cuda,\n",
    "    frequency=1,\n",
    "    data_loader_kwargs={\"batch_size\":256},\n",
    "    n_epochs_kl_warmup=200,\n",
    "    n_epochs_back_kl_warmup=200,\n",
    "    early_stopping_kwargs=early_stopping_kwargs,\n",
    "    seed=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(lr=lr, n_epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    print(trainer.validation_set.compute_marginal_log_likelihood(n_samples_mc=100, batch_size=64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-trainer.validation_set.compute_elbo(totalvae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    print(trainer.validation_set.compute_reconstruction_error(totalvae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = np.concatenate([dataset.X, dataset.protein_expression], axis=1)\n",
    "full_dataset = GeneExpressionDataset()\n",
    "full_dataset.populate_from_data(full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(full_dataset.nb_genes, n_latent=20, reconstruction_loss=\"nb\")\n",
    "trainer_vae = UnsupervisedTrainer(vae,\n",
    "                                  full_dataset,\n",
    "                                  train_size=0.90,\n",
    "                                  test_size=0.04,\n",
    "                                  use_cuda=True,\n",
    "                                  frequency=10,\n",
    "                                  seed=5,\n",
    "                                  n_epochs_kl_warmup=200,)\n",
    "trainer_vae.train(n_epochs=500, lr=3e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scvi.models.log_likelihood import compute_marginal_log_likelihood, compute_elbo, compute_reconstruction_error\n",
    "with torch.no_grad():\n",
    "    print(compute_marginal_log_likelihood(vae, trainer_vae.validation_set, n_samples_mc=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(trainer.history['elbo_validation_set'][50:], label=\"validation\")\n",
    "plt.plot(trainer.history['elbo_train_set'][50:], label=\"train\")\n",
    "plt.plot(trainer.history['elbo_test_set'][50:], label=\"test\")\n",
    "# plt.ylim(2500, 2600)\n",
    "sns.despine()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(trainer.history['elbo_validation_set'][10:], label=\"validation\")\n",
    "plt.plot(trainer.history['elbo_test_set'][10:], label=\"test\")\n",
    "# plt.ylim(2500, 2700)\n",
    "sns.despine()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(trainer_vae.history['elbo_validation_set'][10:], label=\"validation\")\n",
    "plt.plot(trainer_vae.history['elbo_test_set'][10:], label=\"test\")\n",
    "# plt.ylim(2500, 2700)\n",
    "sns.despine()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    print(-trainer.validation_set.compute_elbo(totalvae))\n",
    "    print(-compute_elbo(vae, trainer_vae.validation_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_posterior = trainer.create_posterior(totalvae, dataset, indices=np.arange(len(dataset)), type_class=TotalPosterior)\n",
    "latent_mean, batch_index, label, library_gene = full_posterior.sequential().get_latent()\n",
    "latent = full_posterior.sequential().get_latent(sample=True)[0]\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "N_SAMPLES = 50\n",
    "parsed_protein_names = [p.split(\"_\")[0] for p in dataset.protein_names]\n",
    "py_mixing = sigmoid(full_posterior.sequential().get_sample_mixing(n_samples=N_SAMPLES, give_mean=True))\n",
    "protein_pi = pd.DataFrame(data=py_mixing, columns=parsed_protein_names)\n",
    "denoised_data = np.concatenate(full_posterior.sequential().get_normalized_denoised_expression(n_samples=N_SAMPLES, give_mean=True), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_post = trainer_vae.create_posterior(vae, full_dataset, indices=np.arange(len(dataset)))\n",
    "ppc_held = totalPPC(posteriors_dict={'totalVI':trainer.validation_set, \"scVI\":trainer_vae.validation_set}, n_samples=150)\n",
    "ppc_full = totalPPC(posteriors_dict={'totalVI':full_posterior, \"scVI\":vae_post}, n_samples=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = trainer.train_set.indices\n",
    "test_indices = trainer.validation_set.indices\n",
    "train_data = full_data[trainer.train_set.indices]\n",
    "ppc_held.store_fa_samples(train_data, train_indices, test_indices, n_components=totalvae.n_latent, normalization=\"log\")\n",
    "ppc_held.store_fa_samples(train_data, train_indices, test_indices, n_components=totalvae.n_latent, normalization=\"log_rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibration_error(ppc, key):\n",
    "    ps = [2.5, 5, 7.5, 10, 12.5, 15, 17.5, 82.5, 85, 87.5, 90, 92.5, 95, 97.5]\n",
    "#     ps = [25, 30, 35, 40, 45, 55, 60, 65, 70, 75]\n",
    "    reverse_ps = ps[::-1]\n",
    "    percentiles = np.percentile(ppc.posterior_predictive_samples[key], ps, axis=2)\n",
    "    reverse_percentiles = percentiles[::-1]\n",
    "    cal_error_genes = 0\n",
    "    cal_error_proteins = 0\n",
    "    cal_error_total = 0\n",
    "    for i, j, truth, reverse_truth in zip(percentiles, reverse_percentiles, ps, reverse_ps):\n",
    "        if truth > reverse_truth:\n",
    "            break\n",
    "        ci = np.logical_and(ppc.raw_counts >= i, ppc.raw_counts <= j)\n",
    "        pci_genes = np.mean(ci[:, :dataset.nb_genes])\n",
    "        pci_proteins = np.mean(ci[:, dataset.nb_genes:])\n",
    "        pci_total = np.mean(ci)\n",
    "        true_width = (100 - truth * 2) / 100\n",
    "        cal_error_genes += (pci_genes - true_width)**2\n",
    "        cal_error_proteins += (pci_proteins - true_width)**2\n",
    "        cal_error_total += (pci_total - true_width)**2\n",
    "    print(cal_error_genes, cal_error_proteins, cal_error_total)\n",
    "\n",
    "calibration_error(ppc_held, \"totalVI\")\n",
    "calibration_error(ppc_held, \"scVI\")\n",
    "calibration_error(ppc_held, \"Factor Analysis (Log)\")\n",
    "calibration_error(ppc_held, \"Factor Analysis (Log Rate)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_log_error(self):\n",
    "    df = pd.DataFrame()\n",
    "    for m, samples in self.posterior_predictive_samples.items():\n",
    "        mean_sample = np.mean(samples, axis=-1)\n",
    "        mad_gene = np.mean(\n",
    "            np.square(\n",
    "                np.log(mean_sample[:, : self.dataset.nb_genes] + 1)\n",
    "                - np.log(self.raw_counts[:, : self.dataset.nb_genes] + 1)\n",
    "            )\n",
    "        )\n",
    "        mad_pro = np.mean(\n",
    "            np.square(\n",
    "                np.log(mean_sample[:, self.dataset.nb_genes :] + 1)\n",
    "                - np.log(self.raw_counts[:, self.dataset.nb_genes :] + 1)\n",
    "            )\n",
    "        )\n",
    "        df[m] = [mad_gene, mad_pro]\n",
    "\n",
    "    df.index = [\"genes\", \"proteins\"]\n",
    "    self.metrics[\"msle\"] = df\n",
    "mean_squared_log_error(ppc_held)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppc_held.metrics[\"msle\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ppc_held\n",
    "ppc_full.store_fa_samples(ppc_full.raw_counts, np.arange(len(dataset)), np.arange(len(dataset)), \n",
    "                          n_components=totalvae.n_latent, normalization=\"log\")\n",
    "ppc_full.store_fa_samples(ppc_full.raw_counts, np.arange(len(dataset)), np.arange(len(dataset)), \n",
    "                          n_components=totalvae.n_latent, normalization=\"log_rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppc = ppc_full\n",
    "ppc.coeff_of_variation(cell_wise=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "sns.boxplot(data=ppc.metrics[\"cv_gene\"].iloc[dataset.nb_genes:], ax=ax, showfliers=False)\n",
    "plt.title(\"Coefficient of Variation (Proteins)\")\n",
    "sns.despine()\n",
    "key = \"cv_gene\"\n",
    "print(np.median(np.abs(ppc.metrics[key][\"totalVI\"].iloc[dataset.nb_genes:] - ppc.metrics[key][\"raw\"].iloc[dataset.nb_genes:])))\n",
    "\n",
    "print(np.median(np.abs(ppc.metrics[key][\"scVI\"].iloc[dataset.nb_genes:] - ppc.metrics[key][\"raw\"].iloc[dataset.nb_genes:])))\n",
    "\n",
    "print(np.median(np.abs(ppc.metrics[key][\"Factor Analysis (Log)\"].iloc[dataset.nb_genes:] - ppc.metrics[key][\"raw\"].iloc[dataset.nb_genes:])))\n",
    "\n",
    "print(np.median(np.abs(ppc.metrics[key][\"Factor Analysis (Log Rate)\"].iloc[dataset.nb_genes:] - ppc.metrics[key][\"raw\"].iloc[dataset.nb_genes:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "sns.boxplot(data=ppc.metrics[\"cv_gene\"].iloc[:dataset.nb_genes], ax=ax, showfliers=False)\n",
    "plt.title(\"Coefficient of Variation (RNA)\")\n",
    "sns.despine()\n",
    "key = \"cv_gene\"\n",
    "print(np.median(np.abs(ppc.metrics[key][\"totalVI\"].iloc[:dataset.nb_genes] - ppc.metrics[key][\"raw\"].iloc[:dataset.nb_genes])))\n",
    "\n",
    "print(np.median(np.abs(ppc.metrics[key][\"Factor Analysis (Log)\"].iloc[:dataset.nb_genes] - ppc.metrics[key][\"raw\"].iloc[:dataset.nb_genes])))\n",
    "\n",
    "print(np.median(np.abs(ppc.metrics[key][\"Factor Analysis (Log Rate)\"].iloc[:dataset.nb_genes] - ppc.metrics[key][\"raw\"].iloc[:dataset.nb_genes])))\n",
    "\n",
    "print(np.median(np.abs(ppc.metrics[key][\"scVI\"].iloc[:dataset.nb_genes] - ppc.metrics[key][\"raw\"].iloc[:dataset.nb_genes])))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "private_scvi",
   "language": "python",
   "name": "private_scvi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
